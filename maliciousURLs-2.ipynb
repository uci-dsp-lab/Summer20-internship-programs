{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    count\n",
       "0      1    56937\n",
       "1      0  1000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import NGram,HashingTF, IDF\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.mllib.feature import StandardScaler, StandardScalerModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row,SparkSession\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark import SparkConf, SQLContext, SparkContext\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Detecting-Malicious-URL-App\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "#Reading in the URL file and storing into dataframe\n",
    "data_df = spark.read.csv(path='/C:/Users/Timothy/Downloads/Detecting-Malicious-URL-Machine-Learning-master/dataset.csv',\n",
    "                        sep=',',\n",
    "                        encoding='UTF-8',\n",
    "                        comment=None,\n",
    "                        header=True, \n",
    "                        inferSchema=True)\n",
    "\n",
    "data_df.groupby('label').count().toPandas()\n",
    "\n",
    "#data_df = pd.read_csv('Downloads/Detecting-Malicious-URL-Machine-Learning-master/dataset.csv')\n",
    "\n",
    "#data_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "undersample to make it balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleRatio =  0.053869814378718885\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>53906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  count\n",
       "0      1  56937\n",
       "1      0  53906"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malicious = data_df.filter(\"label = 1\") #Filters the malicious URLs\n",
    "benign = data_df.filter(\"label = 0\") #Filters the benign URLs\n",
    "\n",
    "sampleRatio = malicious.count() / data_df.count() #Calculates the fraction of malicious URLs in the dataset\n",
    "print(\"sampleRatio = \", sampleRatio) #Displays the calculated fraction of malicious URLs\n",
    "sample_benign = benign.sample(False, sampleRatio) #Takes a sample of benign URLs around the same amount as malicious URLs\n",
    "\n",
    "sampled = malicious.unionAll(sample_benign) #Combines the sampled benign URLs with the malicious URLs\n",
    "sampled.groupby('label').count().toPandas() #Groups the new sample by benign/malicious and displays the numbers of each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Ingestion and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Dataset Count: 88524\n",
      "Test Dataset Count: 22319\n",
      "Total Dataset Count: 110843\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|                 url|label|               Words|         rawfeatures|            features|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|http://br-ofertas...|    1|[http, br, oferta...|(6988,[0,1,2,3,18...|(6988,[0,1,2,3,18...|\n",
      "|https://semana-da...|    1|[https, semana, d...|(6988,[0,3,6,18,2...|(6988,[0,3,6,18,2...|\n",
      "|https://scrid-app...|    1|[https, scrid, ap...|(6988,[0,6,844],[...|(6988,[0,6,844],[...|\n",
      "|http://my-softban...|    1|[http, my, softba...|(6988,[0,1,29,162...|(6988,[0,1,29,162...|\n",
      "|http://www.my-sof...|    1|[http, www, my, s...|(6988,[0,1,4,29,1...|(6988,[0,1,4,29,1...|\n",
      "|http://diadesalda...|    1|[http, diadesalda...|(6988,[0,1],[1.0,...|(6988,[0,1],[0.55...|\n",
      "|https://sites.goo...|    1|[https, sites, go...|(6988,[0,6,27,30,...|(6988,[0,6,27,30,...|\n",
      "|http://protvinowi...|    1|[http, protvinowi...|(6988,[1,14],[1.0...|(6988,[1,14],[0.8...|\n",
      "|http://socset222....|    1|[http, socset222,...|(6988,[1,283,465]...|(6988,[1,283,465]...|\n",
      "|https://help78.00...|    1|[https, help78, 0...|(6988,[0,3,6,50,2...|(6988,[0,3,6,50,2...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tokennize the TrainData - sparse the URL string into words\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"url\", outputCol=\"Words\", pattern=\"\\\\W\")\n",
    "\n",
    "#CountVectorizer converts the the words into feature vectors - Thi is used as it gives better results\n",
    "countVectors = CountVectorizer(inputCol=regexTokenizer.getOutputCol(), outputCol=\"rawfeatures\", vocabSize=10000, minDF=5)\n",
    "\n",
    "#\n",
    "idf = IDF(inputCol=countVectors.getOutputCol(), outputCol=\"features\") \n",
    "\n",
    "#create the pipline \n",
    "pipeline = Pipeline(stages=[regexTokenizer, countVectors, idf ])\n",
    "\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "# Pass 'sampled' in the param to set Balanced datasets\n",
    "pipelineFit = pipeline.fit(sampled)\n",
    "\n",
    "#Transform the pipeline to dataset\n",
    "# Pass 'sampled' in the param to set Balanced datasets\n",
    "dataset = pipelineFit.transform(sampled)\n",
    "\n",
    "#randomly split the dataset to traning and testing 80%, 20% respectively\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"\\nTraining Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))\n",
    "print(\"Total Dataset Count: \" + str(dataset.count()))\n",
    "\n",
    "dataset.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                 url|label|               Words|         rawfeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|       2amsports.com|    1|    [2amsports, com]|    (6988,[0],[1.0])|(6988,[0],[0.5561...|[4.57140644683777...|[0.98976248865805...|       0.0|\n",
      "|TRIANGLESERVICESL...|    1|[triangleservices...|    (6988,[0],[1.0])|(6988,[0],[0.5561...|[4.57140644683777...|[0.98976248865805...|       0.0|\n",
      "|above.e-rezerwacj...|    1|[above, e, rezerw...|(6988,[42,94],[1....|(6988,[42,94],[4....|[4.37659996444787...|[0.98758797676265...|       0.0|\n",
      "|     ad.getfond.info|    1| [ad, getfond, info]|(6988,[34,527],[1...|(6988,[34,527],[4...|[-2.0614051677728...|[0.11290501544829...|       1.0|\n",
      "|adserving.favorit...|    1|[adserving, favor...|(6988,[0,447],[1....|(6988,[0,447],[0....|[8.68830797173570...|[0.99983148343468...|       0.0|\n",
      "|        agsteier.com|    1|     [agsteier, com]|    (6988,[0],[1.0])|(6988,[0],[0.5561...|[4.57140644683777...|[0.98976248865805...|       0.0|\n",
      "|    akirkpatrick.com|    1| [akirkpatrick, com]|    (6988,[0],[1.0])|(6988,[0],[0.5561...|[4.57140644683777...|[0.98976248865805...|       0.0|\n",
      "|       alegroup.info|    1|    [alegroup, info]|   (6988,[34],[1.0])|(6988,[34],[4.181...|[3.34709150527887...|[0.96600946422789...|       0.0|\n",
      "|alexandria90.etcs...|    1|[alexandria90, et...|    (6988,[0],[1.0])|(6988,[0],[0.5561...|[4.57140644683777...|[0.98976248865805...|       0.0|\n",
      "|          alisat.biz|    1|       [alisat, biz]|  (6988,[118],[1.0])|(6988,[118],[5.66...|[4.89829228337460...|[0.99259591875260...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Accuracy :  0.9918903176665621\n",
      "Precision:  0.9964371604168523\n",
      "Recall :  0.987552966101695\n",
      "F Score :  0.9919751718022612\n"
     ]
    }
   ],
   "source": [
    "#Importing modules for Logistic Regression\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "\n",
    "#Instantiating, training, and testing the model\n",
    "log_reg = LogisticRegression()\n",
    "logModel = log_reg.fit(trainingData)\n",
    "predictions = logModel.transform(testData)\n",
    "predictions.show(10)\n",
    "\n",
    "#Calculating and displaying the accuracy of the model\n",
    "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(predictions.count())\n",
    "print(\"Accuracy : \",accuracy)\n",
    "\n",
    "#Calculating the amount of true positives, true negatives, false positives, and false negatives from the model\n",
    "df = predictions.select('prediction', 'label')\n",
    "\n",
    "tp = df[(df.label == 1) & (df.prediction == 1)].count() #True positive\n",
    "tn = df[(df.label == 0) & (df.prediction == 0)].count() #True negative\n",
    "fp = df[(df.label == 0) & (df.prediction == 1)].count() #False positive\n",
    "fn = df[(df.label == 1) & (df.prediction == 0)].count() #False negative\n",
    "\n",
    "#Calculating precision, recall, and F score\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f = 2 * (precision * recall)/(precision + recall)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall : \", recall)\n",
    "print(\"F Score : \",f)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                 url|label|               Words|         rawfeatures|            features|       rawPrediction|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|       2amsports.com|    1|    [2amsports, com]|    (6988,[0],[1.0])|(6988,[0],[0.5561...|[1.05899563413891...|       0.0|\n",
      "|TRIANGLESERVICESL...|    1|[triangleservices...|    (6988,[0],[1.0])|(6988,[0],[0.5561...|[1.05899563413891...|       0.0|\n",
      "|above.e-rezerwacj...|    1|[above, e, rezerw...|(6988,[42,94],[1....|(6988,[42,94],[4....|[1.05551590276667...|       0.0|\n",
      "|     ad.getfond.info|    1| [ad, getfond, info]|(6988,[34,527],[1...|(6988,[34,527],[4...|[-1.0451741689724...|       1.0|\n",
      "|adserving.favorit...|    1|[adserving, favor...|(6988,[0,447],[1....|(6988,[0,447],[0....|[1.47156802141571...|       0.0|\n",
      "|        agsteier.com|    1|     [agsteier, com]|    (6988,[0],[1.0])|(6988,[0],[0.5561...|[1.05899563413891...|       0.0|\n",
      "|    akirkpatrick.com|    1| [akirkpatrick, com]|    (6988,[0],[1.0])|(6988,[0],[0.5561...|[1.05899563413891...|       0.0|\n",
      "|       alegroup.info|    1|    [alegroup, info]|   (6988,[34],[1.0])|(6988,[34],[4.181...|[1.00088872901085...|       0.0|\n",
      "|alexandria90.etcs...|    1|[alexandria90, et...|    (6988,[0],[1.0])|(6988,[0],[0.5561...|[1.05899563413891...|       0.0|\n",
      "|          alisat.biz|    1|       [alisat, biz]|  (6988,[118],[1.0])|(6988,[118],[5.66...|[1.11631496245556...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Accuracy :  0.9929208297862807\n",
      "Precision:  0.9977718360071302\n",
      "Recall :  0.9882591807909604\n",
      "F Score :  0.9929927266276387\n"
     ]
    }
   ],
   "source": [
    "#Importing Support Vector Machine\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "#Instantiating, training, and testing the model\n",
    "lsvc = LinearSVC()\n",
    "lsvcModel = lsvc.fit(trainingData)\n",
    "svcpredict = lsvcModel.transform(testData)\n",
    "svcpredict.show(10)\n",
    "\n",
    "#Calculating and displaying the accuracy of the model\n",
    "accuracy = svcpredict.filter(svcpredict.label == svcpredict.prediction).count() / float(svcpredict.count())\n",
    "print(\"Accuracy : \",accuracy)\n",
    "\n",
    "#Calculating the amount of true positives, true negatives, false positives, and false negatives from the model\n",
    "df = svcpredict.select('prediction', 'label')\n",
    "\n",
    "tp = df[(df.label == 1) & (df.prediction == 1)].count() #True positive\n",
    "tn = df[(df.label == 0) & (df.prediction == 0)].count() #True negative\n",
    "fp = df[(df.label == 0) & (df.prediction == 1)].count() #False positive\n",
    "fn = df[(df.label == 1) & (df.prediction == 0)].count() #False negative\n",
    "\n",
    "#Calculating precision, recall, and F score\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f = 2 * (precision * recall)/(precision + recall)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall : \", recall)\n",
    "print(\"F Score : \",f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
